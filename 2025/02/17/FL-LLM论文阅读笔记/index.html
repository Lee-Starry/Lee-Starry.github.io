<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>FL-LLM-FedPepTAO | Starry的小屋</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Federated Learning of Large Language Models with Parameter-Efficient Prompt Tuning and Adaptive Optimization基于高效参数调整的prompt训练和自适应优化的大型语言模型的联邦学习针对利用联邦学习的方法进行大语言模型训练时庞大的通信成本和数据不独立同分布带来的客户端漂移问题，提出一种能够自适应">
<meta property="og:type" content="article">
<meta property="og:title" content="FL-LLM-FedPepTAO">
<meta property="og:url" content="http://example.com/2025/02/17/FL-LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Starry的小屋">
<meta property="og:description" content="Federated Learning of Large Language Models with Parameter-Efficient Prompt Tuning and Adaptive Optimization基于高效参数调整的prompt训练和自适应优化的大型语言模型的联邦学习针对利用联邦学习的方法进行大语言模型训练时庞大的通信成本和数据不独立同分布带来的客户端漂移问题，提出一种能够自适应">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-02-17T05:38:42.000Z">
<meta property="article:modified_time" content="2025-03-11T07:50:41.288Z">
<meta property="article:author" content="Starry">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Starry的小屋" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Starry的小屋</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS 订阅"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="搜索"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-FL-LLM论文阅读笔记" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/02/17/FL-LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" class="article-date">
  <time class="dt-published" datetime="2025-02-17T05:38:42.000Z" itemprop="datePublished">2025-02-17</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      FL-LLM-FedPepTAO
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="Federated-Learning-of-Large-Language-Models-with-Parameter-Efficient-Prompt-Tuning-and-Adaptive-Optimization"><a href="#Federated-Learning-of-Large-Language-Models-with-Parameter-Efficient-Prompt-Tuning-and-Adaptive-Optimization" class="headerlink" title="Federated Learning of Large Language Models with Parameter-Efficient Prompt Tuning and Adaptive Optimization"></a>Federated Learning of Large Language Models with Parameter-Efficient Prompt Tuning and Adaptive Optimization</h2><h2 id="基于高效参数调整的prompt训练和自适应优化的大型语言模型的联邦学习"><a href="#基于高效参数调整的prompt训练和自适应优化的大型语言模型的联邦学习" class="headerlink" title="基于高效参数调整的prompt训练和自适应优化的大型语言模型的联邦学习"></a>基于高效参数调整的prompt训练和自适应优化的大型语言模型的联邦学习</h2><p>针对利用联邦学习的方法进行大语言模型训练时<strong>庞大的通信成本</strong>和数据不独立同分布带来的<strong>客户端漂移问题</strong>，提出一种能够自适应优化的有效微调方式<strong>FedPepTAO</strong></p>
<span id="more"></span>

<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ol>
<li>LLM重要参数的更新限制了使用FL进行LLM训练的可行性</li>
<li>Prompt优化可以显著减少LLM训练中更新的参数数量，但也会造成性能退化或训练效率降低</li>
<li>在FL上直接使用prompt优化会造成显著的通信成本增加和性能降低</li>
<li>分散保存的数据往往不是独立同分布的，因此会出现客户端漂移问题(client drift problems)并造成不好的表现</li>
<li>直接应用自适应最优化的方法可能会导致训练过程中的收敛性问题</li>
<li>在单个方面的自适应优化的应用可能对应于较差的性能</li>
<li>当双方都利用自适应优化时可能会产生沉重的通信成本</li>
</ol>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>一种带有自适应优化的有效提示微调方法<strong>FedPepTAO</strong></p>
<ol>
<li>一种高效的参数更新方法，根据每层的重要性来选择合适的提示层进行参数传递，以减少在所有提示层中传递整套参数带来的沉重的通信成本</li>
<li>一种评分方法，根据该层对最终收敛精度的调优影响来识别每一层的重要性。</li>
<li>一种在服务器端和设备端的自适应优化方法，对每个设备进行控制措施，以达到极好的精度</li>
</ol>
<h2 id="FedPepTAO"><a href="#FedPepTAO" class="headerlink" title="FedPepTAO"></a>FedPepTAO</h2><h3 id="系统模型"><a href="#系统模型" class="headerlink" title="系统模型"></a>系统模型</h3><p>设备：一台参数服务器和许多参与训练的设备</p>
<p>在训练过程中，每一层的LLM只进行推理，而prompt模块则进行推理和参数的更新。在FL调优过程中，特定层的提示参数在设备和服务器之间进行通信。</p>
<p>在FedPepTAO的FL调优过程中，对每个设备的prompt参数进行多轮更新。每一轮包括五个步骤：</p>
<ol>
<li>选择一组设备执行prompt参数的更新</li>
<li>这些设备从服务器接收相应的特定层的被更新prompt参数</li>
<li>每个设备基于各自的数据用自适应优化方法对prompt参数进行更新</li>
<li>特定层的prompt参数被传回给服务器</li>
<li>prompt参数通过自适应优化方法聚合在服务器上</li>
</ol>
<h3 id="高效的参数更新方法"><a href="#高效的参数更新方法" class="headerlink" title="高效的参数更新方法"></a>高效的参数更新方法</h3><h4 id="如何得到每个设备上每一层的评分"><a href="#如何得到每个设备上每一层的评分" class="headerlink" title="如何得到每个设备上每一层的评分"></a>如何得到每个设备上每一层的评分</h4><ol>
<li><strong>计算隐藏状态</strong>：基于任意激活函数的prompt参数，可以计算出LLM中每一层的每个参数的隐藏状态</li>
<li><strong>计算余弦相似度</strong>：通过构建一个核矩阵来实现，其中每个元素表示两层之间的余弦相似度。</li>
<li><strong>计算特征值</strong>：对核矩阵进行特征值分解，得到每个层对应的特征值。这些特征值反映了层之间的区别程度。</li>
<li><strong>计算层得分</strong>：基于特征值，计算每个层的得分。得分的计算公式考虑了特征值的对数值和其倒数，以避免异常值对得分的影响。</li>
</ol>
<h4 id="如何能够无损选择层，在性能不退化的同时降低通信成本"><a href="#如何能够无损选择层，在性能不退化的同时降低通信成本" class="headerlink" title="如何能够无损选择层，在性能不退化的同时降低通信成本"></a>如何能够无损选择层，在性能不退化的同时降低通信成本</h4><p>在前 t 轮中，所有层的prompt参数在服务器和每个设备之间进行通信；在第 t 轮，执行层的选择：</p>
<ol>
<li><strong>计算参数变化</strong>：在每个设备上，计算当前模型参数与初始模型参数之间的变化（(\Delta_i)）。</li>
<li><strong>计算Hessian矩阵</strong>：使用高效的PyHessian库计算当前模型参数的Hessian矩阵（(H(w_t^i))）。</li>
<li><strong>计算特征值</strong>：计算Hessian矩阵的特征值（(\Lambda_H(w_t^i))），并按升序排列。</li>
<li><strong>构造基函数</strong>：构造一个基函数（(B(\Delta_i))），并计算其Lipschitz常数（(L_i)）。</li>
<li><strong>确定选择条件</strong>：找到满足特定条件的第一个特征值索引（(k_i)），该条件确保选择的层具有足够的区分度。</li>
<li><strong>计算层得分</strong>：对于每个设备上的每个层，根据公式3计算其得分（(\zeta_{i,l})）。</li>
<li><strong>聚合得分</strong>：将每个设备上的层得分根据公式4进行聚合，得到全局的层得分（(\gamma)）。</li>
<li><strong>排序和选择层</strong>：根据全局得分对层进行排序，并选择得分最高的层，直到达到预设的参数比例限制。</li>
</ol>
<p>在接下来的几轮中，将已选定层的集合中的prompt参数在服务器和各个设备之间进行通信</p>
<h3 id="高效通信的自适应优化方法"><a href="#高效通信的自适应优化方法" class="headerlink" title="高效通信的自适应优化方法"></a>高效通信的自适应优化方法</h3><h4 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h4><ul>
<li><strong>M</strong>: 设备集合</li>
<li><strong>w</strong>: 初始模型的提示参数</li>
<li><strong>R</strong>: 最大全局轮数</li>
<li><strong>α</strong>: 本地步长</li>
<li><strong>β</strong>: 动量参数</li>
<li><strong>η</strong>: 全局学习率集合</li>
<li><strong>T</strong>: 每个设备上的本地轮数集合</li>
</ul>
<h4 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h4><ul>
<li><strong>wR</strong>: 最终模型的提示参数</li>
</ul>
<h4 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h4><ol>
<li><p><strong>初始化</strong>：</p>
<ul>
<li>将初始模型参数 <code>w0</code> 设置为 <code>w</code>，并将动量缓冲区 <code>c0_i</code>、<code>c0_g</code>、<code>m0_i</code> 初始化为0，对所有设备 <code>i ∈ M</code>。</li>
</ul>
</li>
<li><p><strong>全局轮数循环</strong>：</p>
<ul>
<li>对于每个全局轮数 <code>r = 1, · · · , R</code>：<ul>
<li><strong>随机选择设备子集</strong>：从设备集合 <code>M</code> 中随机抽样一个子集 <code>S</code>。</li>
<li><strong>设备更新</strong>：对每个设备 <code>i ∈ S</code>：<ul>
<li>将上一轮的模型参数 <code>wr−1</code> 发送到设备 <code>i</code>，并初始化本地动量缓冲区 <code>mr,0_i</code> 和 <code>vr,0_i</code> 为0。</li>
<li><strong>本地训练轮数循环</strong>：对每个本地轮数 <code>t = 1, 2, · · · , Ti</code>：<ul>
<li>计算当前模型参数 <code>wr,t−1_i</code> 的梯度 <code>gr,t_i</code>。</li>
<li>使用Adam优化器更新模型参数 <code>wr,t_i</code>、动量缓冲区 <code>mr,t_i</code> 和 <code>vr,t_i</code>。</li>
</ul>
</li>
<li>计算设备 <code>i</code> 的提示参数累计差异 <code>∆wr_i</code>。</li>
</ul>
</li>
<li><strong>聚合差异</strong>：根据公式4聚合所有选中设备的提示参数差异 <code>∆wr</code>。</li>
<li><strong>服务器端控制变量计算</strong>：对每个设备 <code>i ∈ S</code>，在服务器端计算控制变量 <code>cr_i</code> 及其差异 <code>∆cr_i</code>。</li>
<li><strong>聚合控制变量差异</strong>：根据公式4聚合所有设备的控制变量差异 <code>∆cr</code>。</li>
<li><strong>更新全局控制变量和梯度</strong>：计算全局控制变量 <code>cr_g</code> 和全局梯度 <code>gr_g</code>。</li>
<li><strong>更新动量和模型参数</strong>：对每个设备 <code>i ∈ S</code>，更新动量 <code>mr_i</code> 和模型参数 <code>wr_i</code>。</li>
<li><strong>聚合全局模型参数和动量</strong>：根据公式4聚合所有设备的模型参数 <code>wr</code> 和动量 <code>mr</code>。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="关键"><a href="#关键" class="headerlink" title="关键"></a>关键</h4><ul>
<li><strong>动量缓冲区重置</strong>：在本地更新开始时，将动量缓冲区重置为零，避免动量变量在服务器和设备之间的额外通信。</li>
<li><strong>控制变量计算</strong>：在服务器端计算控制变量，以避免由非独立同分布（non-IID）数据导致的客户端漂移问题。</li>
<li><strong>通信成本控制</strong>：该方法的通信成本取决于提示参数的大小，与FedAvg类似，但性能更优。</li>
</ul>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><ul>
<li>联邦学习环境：包含100个设备和一个参数服务器的联邦学习环境。</li>
<li>设备选择：在每个轮次中，随机选择10个设备进行本地更新。</li>
<li>训练轮次：全局训练轮次设置为100轮，本地训练轮次设置为2轮。</li>
<li>数据分布：使用Dirichlet分布（浓度参数alpha为1.0）将数据划分为非独立同分布（non-IID）的多个部分，并根据Dirichlet分布（浓度参数alpha为5.0）将一定数量的样本分配给每个设备。</li>
<li>评估方式：对于GLUE基准任务，使用开发集进行评估，因为测试集未标注。对于其他4个数据集，从训练集中选择一定数量的样本作为开发集，每个标签的样本数量根据其在原始训练集中的比例确定。</li>
</ul>
<p>FedPepTAO的评估：</p>
<ul>
<li>准确率：在多个数据集上显著优于基线方法，最高准确率比Adapter、FedPrompt、P-tuning v2等方法高出25.39%、23.83%、14.53%等。</li>
<li>效率：训练时间显著少于其他方法，最高比Adapter、FedPrompt、P-tuning v2等方法快95.91%、95.17%、92.76%等。</li>
</ul>
<p>在其他LLM上的评估：</p>
<ul>
<li>GPT2LARGE模型：FedPepTAO在MRPC、MR和SST-2数据集上显著优于基线方法，准确率最高分别高出32.3%、18.23%、43.32%等。</li>
<li>LLaMA 3B模型：在RTE和MRPC数据集上，FedPepTAO的准确率最高分别高出4.6%、11.29%等。</li>
<li>LLaMA 7B模型：在MRPC数据集上，FedPepTAO的准确率最高高出5.05%。</li>
</ul>
<h2 id="缺陷"><a href="#缺陷" class="headerlink" title="缺陷"></a>缺陷</h2><h3 id="提示参数共享的隐私风险"><a href="#提示参数共享的隐私风险" class="headerlink" title="提示参数共享的隐私风险"></a>提示参数共享的隐私风险</h3><p>涉及到提示参数在客户端和服务器之间的共享。在联邦学习中，共享的参数可能会泄露客户端的隐私信息，尤其是在提示参数与客户端的本地数据高度相关的情况下。</p>
<h3 id="数据集和模型的局限性"><a href="#数据集和模型的局限性" class="headerlink" title="数据集和模型的局限性"></a>数据集和模型的局限性</h3><p>虽然实验涵盖了多个数据集和模型，但可能仍不足以全面代表所有可能的应用场景。例如，实验主要集中在NLP任务上，对于其他类型的机器学习任务（如计算机视觉）的适用性可能需要进一步验证。</p>
<h3 id="实验条件的局限性"><a href="#实验条件的局限性" class="headerlink" title="实验条件的局限性"></a>实验条件的局限性</h3><p>实验中的设备数量和数据分布设置可能与现实世界中的联邦学习场景存在差异，现实中的设备数量可能更多，数据分布可能更加复杂和异构</p>
<h3 id="实现复杂度"><a href="#实现复杂度" class="headerlink" title="实现复杂度"></a>实现复杂度</h3><p>FedPepTAO方法涉及到参数高效提示调优和自适应优化等多个复杂组件，这可能会增加实现和部署的难度。</p>
<h3 id="超参数调优"><a href="#超参数调优" class="headerlink" title="超参数调优"></a>超参数调优</h3><p>该方法可能需要仔细调优多个超参数，如学习率、动量参数等，这在实际应用中可能会增加额外的负担</p>
<h2 id="词语解释"><a href="#词语解释" class="headerlink" title="词语解释"></a>词语解释</h2><h3 id="discrete-space（离散空间）"><a href="#discrete-space（离散空间）" class="headerlink" title="discrete space（离散空间）"></a>discrete space（离散空间）</h3><p>在提示微调的上下文中，离散空间可能指的是对提示进行调整或优化时所涉及的一系列离散的、有限的选项或状态。例如，当对提示中的词汇进行选择或调整时，可使用的词汇集合是有限的、离散的，而不是连续变化的。这意味着在优化过程中，模型需要在有限个可能的词汇中进行选择，以找到最优的组合来引导大语言模型生成更好的输出。这种离散性使得搜索空间变得可管理，但也带来了一定的挑战，因为如何在巨大的离散空间中找到最优解是一个复杂的问题。</p>
<h3 id="continuous-prompts（连续提示）"><a href="#continuous-prompts（连续提示）" class="headerlink" title="continuous prompts（连续提示）"></a>continuous prompts（连续提示）</h3><p>连续提示的概念相对较新，它试图将提示从传统的离散形式扩展到连续空间。在一些研究中，提出了使用连续表示的提示，例如通过学习一个连续的向量来表示提示，而不是仅仅依赖于离散的词汇序列。这种方法认为，连续的表示可以更灵活地捕捉提示的含义和上下文信息，从而有可能提高模型的性能和泛化能力。然而，在联邦学习的大语言模型训练中，直接应用连续提示可能会面临一些困难，如如何在不同的客户端之间有效地共享和同步连续的提示表示等。</p>
<h3 id="client-drift-problem（客户端漂移问题）"><a href="#client-drift-problem（客户端漂移问题）" class="headerlink" title="client drift problem（客户端漂移问题）"></a>client drift problem（客户端漂移问题）</h3><p>在联邦学习过程中，由于各客户端的数据分布不一致（即数据非独立同分布，non-IID），导致不同客户端在本地模型训练时，模型参数的更新方向和程度出现差异，进而使得全局模型在聚合时难以收敛到最优解的现象。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/02/17/FL-LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" data-id="cm79657ls0000mc1h1flu34td" data-title="FL-LLM-FedPepTAO" class="article-share-link"><span class="fa fa-share">分享</span></a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2025/01/20/%E5%AF%86%E7%A0%81%E5%AD%A6%E5%9F%BA%E7%A1%80/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">后一篇</strong>
      <div class="article-nav-title">密码学基础</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/">常用命令</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/">数据库</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">论文阅读笔记</a></li></ul>
    </div>
  </div>


  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/02/">二月 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/01/">一月 2025</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/02/17/FL-LLM%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">FL-LLM-FedPepTAO</a>
          </li>
        
          <li>
            <a href="/2025/01/20/%E5%AF%86%E7%A0%81%E5%AD%A6%E5%9F%BA%E7%A1%80/">密码学基础</a>
          </li>
        
          <li>
            <a href="/2025/01/20/opengauss%E6%95%B0%E6%8D%AE%E5%BA%93%E9%85%8D%E7%BD%AE%E5%8F%8A%E4%BD%BF%E7%94%A8/">opengauss数据库配置及使用</a>
          </li>
        
          <li>
            <a href="/2025/01/20/blog%E7%9B%B8%E5%85%B3/">blog相关</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 Starry<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>